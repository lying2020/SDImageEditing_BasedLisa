#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å•ä¸ªä¾‹å­å›¾åƒç¼–è¾‘ Demo
ä¸éœ€è¦ OpenAI API å’Œ GroundingDINO

è¾“å…¥ï¼š
- source_image: æºå›¾ç‰‡è·¯å¾„
- source_mask: maskå›¾ç‰‡è·¯å¾„ï¼ˆç™½è‰²åŒºåŸŸä¸ºç¼–è¾‘åŒºåŸŸï¼‰
- prompt: ç¼–è¾‘æç¤ºè¯
- editing_type: ç¼–è¾‘ç±»å‹ï¼ˆå¯é€‰ï¼Œæœ‰é»˜è®¤å€¼ï¼‰
- å…¶ä»–å¯é€‰å‚æ•°

è¾“å‡ºï¼š
- ç¼–è¾‘åçš„å›¾ç‰‡ä¿å­˜åœ¨ output/ ç›®å½•
"""

import os
import sys
import torch
from PIL import Image
import numpy as np
from datetime import datetime

# ä» project.py å¯¼å…¥å…¬å…±é…ç½®å’Œå‡½æ•°
import project
from project import (
    load_models,
    EDITING_TYPES,
    DEFAULT_EDITING_TYPE,
    SmartFreeEdit_Pipeline
)


def edit_image(
    pipe,
    source_image_path,
    source_mask_path,
    prompt,
    editing_type=DEFAULT_EDITING_TYPE,
    output_dir="output",
    sample_id=None,
    num_inference_steps=50,
    guidance_scale=7.5,
    control_strength=1.0,
    negative_prompt="ugly, low quality, distorted, blurry",
    blending=True,
):
    """
    ç¼–è¾‘å•ä¸ªå›¾åƒ

    å‚æ•°:
        pipe: StableDiffusionBrushNetPipeline
        source_image_path: æºå›¾ç‰‡è·¯å¾„
        source_mask_path: maskå›¾ç‰‡è·¯å¾„ï¼ˆç™½è‰²åŒºåŸŸä¸ºç¼–è¾‘åŒºåŸŸï¼‰
        prompt: ç¼–è¾‘æç¤ºè¯
        editing_type: ç¼–è¾‘ç±»å‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤å€¼ï¼šLocalï¼‰
            - "Addition": æ·»åŠ å¯¹è±¡
            - "Remove": åˆ é™¤å¯¹è±¡
            - "Local": å±€éƒ¨ç¼–è¾‘/æ›¿æ¢ï¼ˆé»˜è®¤ï¼‰
            - "Global": å…¨å±€ç¼–è¾‘
            - "Background": èƒŒæ™¯æ›¿æ¢
            - "Resize": è°ƒæ•´å¤§å°
        output_dir: è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤ï¼šoutputï¼‰
        sample_id: æ ·æœ¬IDï¼ˆç”¨äºå‘½åè¾“å‡ºæ–‡ä»¶ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ—¶é—´æˆ³ï¼‰
        num_inference_steps: æ¨ç†æ­¥æ•°ï¼ˆé»˜è®¤ï¼š50ï¼‰
        guidance_scale: å¼•å¯¼å¼ºåº¦ï¼ˆé»˜è®¤ï¼š7.5ï¼‰
        control_strength: æ§åˆ¶å¼ºåº¦ï¼ˆé»˜è®¤ï¼š1.0ï¼‰
        negative_prompt: è´Ÿé¢æç¤ºè¯ï¼ˆé»˜è®¤ï¼š"ugly, low quality, distorted, blurry"ï¼‰
        blending: æ˜¯å¦æ··åˆï¼ˆé»˜è®¤ï¼šTrueï¼‰

    è¿”å›:
        ç¼–è¾‘åçš„å›¾ç‰‡è·¯å¾„
    """
    print("\n" + "=" * 60)
    print("å¼€å§‹ç¼–è¾‘å›¾åƒ...")
    print("=" * 60)
    print(f"æºå›¾ç‰‡: {source_image_path}")
    print(f"Maskå›¾ç‰‡: {source_mask_path}")
    print(f"æç¤ºè¯: {prompt}")
    print(f"ç¼–è¾‘ç±»å‹: {editing_type}")

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(source_image_path):
        raise FileNotFoundError(f"æºå›¾ç‰‡ä¸å­˜åœ¨: {source_image_path}")
    if not os.path.exists(source_mask_path):
        raise FileNotFoundError(f"Maskå›¾ç‰‡ä¸å­˜åœ¨: {source_mask_path}")

    # éªŒè¯ç¼–è¾‘ç±»å‹
    if editing_type not in project.EDITING_TYPES:
        print(f"âš ï¸  è­¦å‘Šï¼šç¼–è¾‘ç±»å‹ '{editing_type}' ä¸åœ¨æ”¯æŒåˆ—è¡¨ä¸­ï¼Œä½¿ç”¨é»˜è®¤å€¼ '{project.DEFAULT_EDITING_TYPE}'")
        editing_type = project.DEFAULT_EDITING_TYPE

    # åŠ è½½å›¾ç‰‡
    original_image = np.array(Image.open(source_image_path).convert("RGB"))
    original_mask = np.array(Image.open(source_mask_path).convert("RGB"))

    # å¦‚æœ mask æ˜¯å½©è‰²å›¾ï¼Œè½¬æ¢ä¸ºç°åº¦å›¾ï¼ˆå–ç¬¬ä¸€ä¸ªé€šé“ï¼‰
    if original_mask.ndim == 3:
        original_mask = original_mask[:, :, 0]

    print(f"æºå›¾ç‰‡å°ºå¯¸: {original_image.shape}")
    print(f"Maskå°ºå¯¸: {original_mask.shape}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if sample_id is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        sample_id = f"sample_{timestamp}"

    output_path = os.path.join(output_dir, f"{sample_id}_result.png")
    mask_save_path = os.path.join(output_dir, f"{sample_id}_mask.png")

    # æ‰§è¡Œç¼–è¾‘
    print("\næ­£åœ¨ç”Ÿæˆ...")
    generator = torch.Generator("cuda" if torch.cuda.is_available() else "cpu").manual_seed(42)

    with torch.autocast("cuda" if torch.cuda.is_available() else "cpu"):
        images, mask_image, mask_np, init_image_np = SmartFreeEdit_Pipeline(
            pipe,
            prompt,
            original_mask,
            original_image,
            generator,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            control_strength=control_strength,
            negative_prompt=negative_prompt,
            num_samples=1,
            blending=blending
        )

    # ä¿å­˜ç»“æœ
    images[0].save(output_path)
    Image.fromarray(original_mask).save(mask_save_path)

    print(f"\nâœ… ç¼–è¾‘å®Œæˆï¼")
    print(f"   ç»“æœå›¾ç‰‡: {output_path}")
    print(f"   Maskå›¾ç‰‡: {mask_save_path}")
    print("=" * 60)

    return output_path, mask_save_path


if __name__ == "__main__":
    print("=" * 60)
    print("å•ä¸ªä¾‹å­å›¾åƒç¼–è¾‘ Demo")
    print("=" * 60)
    print("\næ”¯æŒçš„ç¼–è¾‘ç±»å‹ï¼š")
    for edit_type, description in project.EDITING_TYPES.items():
        marker = " (é»˜è®¤)" if edit_type == project.DEFAULT_EDITING_TYPE else ""
        print(f"  - {edit_type}{marker}: {description}")

    # ============================================
    # é…ç½®å‚æ•°ï¼ˆä¿®æ”¹è¿™é‡Œä»¥è¿è¡Œï¼‰
    # ============================================
    source_image_path = "/home/liying/Desktop/IMAGE_EDITE-CVPR-2025/images/ReasonEdit/6-Reasoning/009.png"
    source_mask_path = "/home/liying/Desktop/IMAGE_EDITE-CVPR-2025/images/ReasonEdit/6-Reasoning/009_mask.jpg"  # å¦‚æœä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»º
    prompt = "a carrot"  # ç¼–è¾‘æç¤ºè¯
    editing_type = "Local"  # ç¼–è¾‘ç±»å‹ï¼ˆå¯é€‰ï¼‰
    sample_id = "009_carrot"  # æ ·æœ¬IDï¼ˆå¯é€‰ï¼Œç”¨äºå‘½åè¾“å‡ºæ–‡ä»¶ï¼‰

    # é«˜çº§å‚æ•°ï¼ˆå¯é€‰ï¼Œä½¿ç”¨é»˜è®¤å€¼å³å¯ï¼‰
    num_inference_steps = 50
    guidance_scale = 7.5
    control_strength = 1.0
    negative_prompt = "ugly, low quality, distorted, blurry"
    blending = True

    # ============================================
    # æ£€æŸ¥é…ç½®
    # ============================================
    if not os.path.exists(source_image_path):
        print(f"\nâŒ é”™è¯¯ï¼šæºå›¾ç‰‡ä¸å­˜åœ¨: {source_image_path}")
        print("   è¯·ä¿®æ”¹è„šæœ¬ä¸­çš„ source_image_path å˜é‡")
        sys.exit(1)

    if not os.path.exists(source_mask_path):
        print(f"\nâš ï¸  è­¦å‘Šï¼šMaskå›¾ç‰‡ä¸å­˜åœ¨: {source_mask_path}")
        print("   è¯·åˆ›å»º mask å›¾ç‰‡ï¼ˆç™½è‰²åŒºåŸŸè¡¨ç¤ºè¦ç¼–è¾‘çš„åŒºåŸŸï¼‰")
        sys.exit(1)

    # ============================================
    # åŠ è½½æ¨¡å‹å¹¶æ‰§è¡Œç¼–è¾‘
    # ============================================
    try:
        # åŠ è½½æ¨¡å‹
        pipe = load_models()

        # æ‰§è¡Œç¼–è¾‘
        result_path, mask_path = edit_image(
            pipe=pipe,
            source_image_path=source_image_path,
            source_mask_path=source_mask_path,
            prompt=prompt,
            editing_type=editing_type,
            sample_id=sample_id,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale,
            control_strength=control_strength,
            negative_prompt=negative_prompt,
            blending=blending,
        )

        print("\nğŸ‰ ç¼–è¾‘æˆåŠŸå®Œæˆï¼")
        print(f"   ç»“æœå›¾ç‰‡: {result_path}")
        print(f"   Maskå›¾ç‰‡: {mask_path}")

    except Exception as e:
        print(f"\nâŒ ç¼–è¾‘å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
